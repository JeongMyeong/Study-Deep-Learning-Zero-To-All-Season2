{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_sequence, pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예제 데이터\n",
    "- batch size = 5\n",
    "- sequence 중 가장 긴 길이는 13\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_set: ['<pad>', 'g', 'l', 'i', 'p', 's', 'n', 'a', 'h', 'r', 'd', 'c', 'e', 'w', ' ', 't', 'u', 'o', 'm']\n",
      "char_set length :  19\n"
     ]
    }
   ],
   "source": [
    "data = ['hello world',\n",
    "        'midnight',\n",
    "        'calculation',\n",
    "        'path',\n",
    "        'short circuit'\n",
    "       ]\n",
    "\n",
    "char_set = ['<pad>'] + list(set(char for seq in data for char in seq))\n",
    "char2idx = {char: idx for idx, char in enumerate(char_set)}\n",
    "print('char_set:', char_set)\n",
    "print('char_set length : ', len(char_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8, 12,  2,  2, 17, 14, 13, 17,  9,  2, 10])\n",
      "tensor([18,  3, 10,  6,  3,  1,  8, 15])\n",
      "tensor([11,  7,  2, 11, 16,  2,  7, 15,  3, 17,  6])\n",
      "tensor([ 4,  7, 15,  8])\n",
      "tensor([ 5,  8, 17,  9, 15, 14, 11,  3,  9, 11, 16,  3, 15])\n",
      "\n",
      "### lengths :  [11, 8, 11, 4, 13]\n"
     ]
    }
   ],
   "source": [
    "X = [torch.LongTensor([char2idx[char] for char in seq]) for seq in data]\n",
    "\n",
    "for sequence in X:\n",
    "    print(sequence)\n",
    "    \n",
    "# 시퀀스 길이들이 제각각\n",
    "lengths = [len(seq) for seq in X]\n",
    "print('\\n### lengths : ', lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pad_sequence라는 PyTorch 기본 라이브러리 함수를 이용하여 쉽게 padding을 추가할 수 있다.\n",
    "- input이 Tensor들의 list로 주어져야한다. ----> (Tensor가 아닌 Tensor들의 list)\n",
    "- list 안에 있는 각각의 Tensor들의 shape가 (?, a, b, ...) 라고 할 때, ?는 각각 다른 sequnece length\n",
    "- pad_sequence 함수를 쓰면 (T, batch_size, a, b, ...) shape를 가지는 Tensor가 리턴된다.\n",
    "- 만약 pad_sequence에 명시적으로 batch_first=True 파라미터를 주면 (batch_size, T, a, b, ...)shape를 가지는 Tensor가 리턴됨\n",
    "- 기본적으로 패딩 값은 0 으로 되어있지만 padding_value=42와 같이 파라미터를 지정해주면, apdding하는 값도정할 수있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8, 12,  2,  2, 17, 14, 13, 17,  9,  2, 10,  0,  0],\n",
      "        [18,  3, 10,  6,  3,  1,  8, 15,  0,  0,  0,  0,  0],\n",
      "        [11,  7,  2, 11, 16,  2,  7, 15,  3, 17,  6,  0,  0],\n",
      "        [ 4,  7, 15,  8,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 5,  8, 17,  9, 15, 14, 11,  3,  9, 11, 16,  3, 15]])\n",
      "torch.Size([5, 13])\n"
     ]
    }
   ],
   "source": [
    "padded_sequence = pad_sequence(X, batch_first=True)\n",
    "print(padded_sequence)\n",
    "print(padded_sequence.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pack_sequence 함수를 이용하여 PackedSequence 만들기\n",
    "- padding을 추가하지 않고 정확히 주어진 sequence 길이까지만 모델이 연산을 하게끔 만드는 PyTorch의 자료구조\n",
    "- 주어지는 input은 길이에 따른 내림차순으로 정렬되어 있어야 한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 5,  8, 17,  9, 15, 14, 11,  3,  9, 11, 16,  3, 15])\n",
      "tensor([ 8, 12,  2,  2, 17, 14, 13, 17,  9,  2, 10])\n",
      "tensor([11,  7,  2, 11, 16,  2,  7, 15,  3, 17,  6])\n",
      "tensor([18,  3, 10,  6,  3,  1,  8, 15])\n",
      "tensor([ 4,  7, 15,  8])\n"
     ]
    }
   ],
   "source": [
    "sorted_idx = sorted(range(len(lengths)), key = lengths.__getitem__, reverse=True)\n",
    "sorted_X = [X[idx] for idx in sorted_idx]\n",
    "\n",
    "for sequence in sorted_X:\n",
    "    print(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedSequence(data=tensor([ 5,  8, 11, 18,  4,  8, 12,  7,  3,  7, 17,  2,  2, 10, 15,  9,  2, 11,\n",
      "         6,  8, 15, 17, 16,  3, 14, 14,  2,  1, 11, 13,  7,  8,  3, 17, 15, 15,\n",
      "         9,  9,  3, 11,  2, 17, 16, 10,  6,  3, 15]), batch_sizes=tensor([5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 1, 1]), sorted_indices=None, unsorted_indices=None)\n"
     ]
    }
   ],
   "source": [
    "packed_sequence = pack_sequence(sorted_X)\n",
    "print(packed_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding 적용하기\n",
    "- 패딩된 PaddedSequence를 RNN에 input으로 넣어 테스트\n",
    "- 예제에서는 one-hot-character embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 13, 19])\n"
     ]
    }
   ],
   "source": [
    "eye = torch.eye(len(char_set))\n",
    "embedded_tensor = eye[padded_sequence]\n",
    "print(embedded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47, 19])\n"
     ]
    }
   ],
   "source": [
    "embedded_packed_seq = pack_sequence([eye[X[idx]] for idx in sorted_idx])\n",
    "print(embedded_packed_seq.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn =  torch.nn.RNN(input_size=len(char_set), hidden_size=30, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 13, 30])\n",
      "torch.Size([1, 5, 30])\n"
     ]
    }
   ],
   "source": [
    "rnn_output, hidden = rnn(embedded_tensor)\n",
    "print(rnn_output.data.shape)\n",
    "print(hidden.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pad_packed_sequence\n",
    "- PackedSequence를 PaddedSequence로 바꾸어 주는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 13, 19])\n",
      "tensor([13, 11, 11,  8,  4])\n"
     ]
    }
   ],
   "source": [
    "unpacked_sequence, seq_lengths = pad_packed_sequence(embedded_packed_seq, batch_first=True)\n",
    "print(unpacked_sequence.shape)\n",
    "print(seq_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pack_padded_sequence\n",
    "- 반대로 padding된 Tensor인 PaddedSequence를 PackedSequence로 바꾸어주는 함수\n",
    "- input인 PaddedSequence가 길이에 따른 내림차순으로 정렬되어야 한다는 조건이 성립되어야 PackedSequence로 올바르게 변환될 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 13, 19])\n"
     ]
    }
   ],
   "source": [
    "embedded_padded_sequence = eye[pad_sequence(sorted_X, batch_first=True)]\n",
    "print(embedded_padded_sequence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47, 19])\n",
      "tensor([5, 5, 5, 5, 4, 4, 4, 4, 3, 3, 3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "sorted_lengths = sorted(lengths, reverse=True)\n",
    "new_packed_sequence = pack_padded_sequence(embedded_padded_sequence, sorted_lengths, batch_first=True)\n",
    "print(new_packed_sequence.data.shape)\n",
    "print(new_packed_sequence.batch_sizes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
